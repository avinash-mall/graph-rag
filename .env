# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_TITLE="Graph RAG API"
APP_DESCRIPTION="Graph RAG API combining document and search services"
APP_VERSION=1.0.0

# Graph and Neo4j Configuration
GRAPH_NAME=entityGraph
DB_URL=bolt://localhost:7687
DB_USERNAME=neo4j
DB_PASSWORD=neo4j123

# OpenAI Configuration
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_MODEL=deepseek-r1:14b
#OPENAI_BASE_URL="http://localhost:11434/v1/chat/completions"
OPENAI_BASE_URL="http://localhost/v1/chat/completions"
OPENAI_TEMPERATURE=0.0
# ollama
OPENAI_STOP='["<|end_of_text|>", "<|end_header_id|>", "<|eot_id|>"]'
# llamafile
# OPENAI_STOP='["<|end_of_text|>", "<|eot_id|>"]'

# Chunking and Global Search Defaults
CHUNK_SIZE_GDS=512
GLOBAL_SEARCH_CHUNK_SIZE=512
GLOBAL_SEARCH_TOP_N=30
GLOBAL_SEARCH_BATCH_SIZE=10
RELEVANCE_THRESHOLD=0.40
COREF_WORD_LIMIT=8000
COSINE_EPSILON=1e-8
NER_MAX_RETRIES=3
SUMMARY_TRUNCATE_CHARS=200
RELEVANCE_SCORE_MAX=100
RELEVANCE_SCORE_MIN=1
# Cypher Search
CYPHER_QUERY_LIMIT=5
FALLBACK_SIMILARITY_THRESHOLD=0.0
FALLBACK_JARO_THRESHOLD=0.8
FALLBACK_ENTITY_LIMIT=3
FALLBACK_QUERY_LIMIT=3
# Local Search
LOCAL_SEARCH_RELEVANCE_THRESHOLD=0.3
LOCAL_SEARCH_TOP_K=3
# Embedding API Configuration
EMBEDDING_MODEL_NAME=mxbai-embed-large

EMBEDDING_API_URL="http://localhost:11434/api/embed"
API_TIMEOUT=600

# Logging Configuration (optional)
LOG_DIR=logs
LOG_FILE=app.log
LOG_LEVEL=DEBUG

# Prompts
NER_EXTRACTION_PROMPT="Extract all named entities from the following text. For each entity, provide its name and type (e.g., cardinal value, date value, event name, building name, geo-political entity, language name, law name, money name, person name, organization name, location name, affiliation, ordinal value, percent value, product name, quantity value, time value, name of work of art). If uncertain, label it as 'UNKNOWN'. Return ONLY a valid Python list of dictionaries (without any additional text or markdown) in the exact format as example below: [{'name': 'Entity1', 'type': 'Type1'}, {'name': 'Entity2', 'type': 'Type3'}, ...].\n\n"
NER_SYSTEM_PROMPT="You are a professional NER extraction assistant who responds only in valid python list of dictionaries."
SYSTEM_MESSAGE_GENERIC="You are a professional assistant. Please provide a detailed answer."
RERANKING_PROMPT="You are an expert in evaluating textual information. Below are several community summaries. For the given user query, please rank these summaries in order of relevance from most to least relevant. For each summary, provide a JSON object containing:\n  - 'report_index': the index number (starting from 1) of the summary as listed below\n  - 'score': an integer between {RELEVANCE_SCORE_MIN} and {RELEVANCE_SCORE_MAX} indicating its relevance ({RELEVANCE_SCORE_MAX} being most relevant)\n Return the results as a JSON array sorted in descending order by score.\n User Query: {question}\n Community Summaries:\n"
RERANKING_SYSTEM_PROMPT="You are an expert at ranking textual information."

COREF_SYSTEM_PROMPT="You are a professional text refiner skilled in coreference resolution."
COREF_USER_PROMPT="Resolve all ambiguous pronouns and vague references in the following text by replacing them with their appropriate entities. Ensure no unresolved pronouns like 'he', 'she', 'himself', etc. remain. If the referenced entity is unclear, make an intelligent guess based on context.\n\n"
SUMMARY_SYSTEM_PROMPT="You are a professional summarization assistant. Do not use your prior knowledge and only use knowledge from the provided text."
SUMMARY_USER_PROMPT="Summarize the following text into a meaningful summary with key insights. If the text is too short or unclear, describe the entities and their possible connections. Avoid vague fillers.\n\n"

REWRITE_SYSTEM_PROMPT="You are a professional query rewriting assistant."
REWRITE_USER_PROMPT="Based on the previous conversation: '{conversation}', rewrite the query: '{question}' into a standalone query."
GSEARCH_EXTRACT_SYSTEM_PROMPT="You are a professional extraction assistant."
GSEARCH_EXTRACT_USER_PROMPT="You are an expert in extracting key points. For the following text chunks from a community summary, list the key points that are most relevant to answering the user query. For each key point, provide a brief description and assign a relevance rating between 1 and 100. Format each key point on a separate line in this format:\nKey point: <description> (Rating: <number>)"

GSEARCH_RERANK_SYSTEM_PROMPT="You are an expert at ranking key points."
GSEARCH_RERANK_USER_PROMPT="You are an expert at evaluating the relevance of key points extracted from community summaries. Below are key points extracted from the documents, each on a separate line. Please rerank them in descending order of relevance to the following user query, and output the reranked key points as a plain text list, each on a separate line.\nUser Query: {question}\nKey Points:\n{points}"
GSEARCH_FINAL_SYSTEM_PROMPT="You are a professional assistant providing detailed answers."

LSEARCH_SYSTEM_PROMPT="You are a professional assistant who answers strictly based on the provided context."
LSEARCH_USER_PROMPT="You are a professional assistant who answers queries strictly based on the provided context.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:"

DRIFT_PRIMER_SYSTEM_PROMPT="You are a professional assistant."
DRIFT_PRIMER_USER_PROMPT="You are an expert in synthesizing information from diverse community reports. Based on the following global context derived from document similarity filtering:\n{context}\n{conversation}\nPlease provide a preliminary answer to the following query and list any follow-up questions that could help refine it.\nFormat your response as plain text with the following sections:\n\nIntermediate Answer:\n<your intermediate answer here>\n\nFollow-Up Questions:\n1. <first>\n2. <second>\n..."
DRIFT_LOCAL_SYSTEM_PROMPT="You are a professional assistant."
DRIFT_LOCAL_USER_PROMPT="You are a professional assistant who refines queries using local document context. Based on the following local context:\n{local_context}\n{conversation}\nPlease provide an answer to the following follow-up query and list any additional follow-up questions.\nFormat your response as plain text with these sections:\n\nAnswer:\n<your answer here>\n\nFollow-Up Questions:\n1. <first>\n2. <second>\n...\n\nFollow-Up Query: {query}"
DRIFT_FINAL_SYSTEM_PROMPT="You are a professional assistant."
DRIFT_FINAL_USER_PROMPT="You are a professional assistant tasked with synthesizing a final detailed answer.\nBelow is the hierarchical data gathered:\n\nQuery: {query}\n\nIntermediate Answer: {intermediate}\n\nFollow-Up Interactions:\n{follow_ups}\n\nBased solely on the above, provide a final, comprehensive answer in plain text to the original query:\n{original_query}"
